{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20180418: for bird_tw(73:1812), frog_tw(35:246), dog(15:66). (classNum:fileNum) \n",
    "### 20180419: modifying codes according to Richard's finding for enabling 4 mulit-GPU (search 'config for multi-GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "import os\n",
    "import h5py\n",
    "import sys, getopt\n",
    "import datetime\n",
    "from io_utils_mod import HDF5Matrix\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# from MapCallback import MapCallback\n",
    "\n",
    "### config for multi-GPU ###\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0,1,2,3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5path = '../data/all_data.hdf5' # training data generated by loadData.py\n",
    "modelName2Save = 'trainModel_InceptionV3_1-v5_bird_frog_dog.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hdf5path: ../data/all_data.hdf5, scalerFilePath: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "modelPath = 'InceptionV3' #M: 沒用\n",
    "logfileName = 'log.xls' #M: 沒用\n",
    "#scalerFilePath = '../birdclef_data/standardScaler_5000.pickle'\n",
    "scalerFilePath = None\n",
    "preTrainedModelWeightsPath = None # path and filename to pretrained network: if there is a pretrained network, we can load it and continue to train it\n",
    "\n",
    "\n",
    "tensorflowBackend = True # set true if Keras has TensorFlow backend - this way we set TF not to allocate all the GPU memory\n",
    "\n",
    "if (tensorflowBackend):\n",
    "    import tensorflow as tf\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth=True\n",
    "    sess = tf.Session(config=config)\n",
    "    from keras import backend as K\n",
    "    K.set_session(sess)\n",
    "\n",
    "print('hdf5path: %s, scalerFilePath: %s' % (hdf5path,scalerFilePath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = None\n",
    "scaleData = None\n",
    "# if a scaler file generated by loadData.py is given, than load it and define a scaler function that will be used later\n",
    "if scalerFilePath is not None:\n",
    "    scaler = pickle.load(open(scalerFilePath, 'rb'))\n",
    "    # Can't use scaler.transform because it only supports 2d arrays.\n",
    "    def scaleData(X):\n",
    "        return (X-scaler.mean_)/scaler.scale_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (18308, 1, 200, 310)\n",
      "dataSetLength=18308\n",
      "output_dim=123\n"
     ]
    }
   ],
   "source": [
    "f = h5py.File(hdf5path, 'r')\n",
    "X = f.get('X')\n",
    "y = f.get('y')\n",
    "print(\"Shape of X:\", X.shape)\n",
    "dataSetLength = X.shape[0]\n",
    "output_dim = y.shape[1] #len(y_train[0])\n",
    "f.close()\n",
    "print('dataSetLength={}'.format(dataSetLength))\n",
    "print('output_dim={}'.format(output_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(HDF5Matrix(hdf5path, 'X', 0, dataSetLength, normalizer = scaleData))\n",
    "y = np.array(HDF5Matrix(hdf5path, 'y', 0, dataSetLength))\n",
    "\n",
    "#M: vvv 再多 shuffle 幾次...\n",
    "X, y = shuffle(X, y, random_state=4)\n",
    "X, y = shuffle(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   X_train, y_train= (14829, 1, 200, 310) (14829, 123) <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "   X_validation, y_validation= (1648, 1, 200, 310) (1648, 123)\n",
      "   X_test, y_test= (1831, 1, 200, 310) (1831, 123)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 4, test_size = 0.1)\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, random_state = 3, test_size = 0.1)\n",
    "\n",
    "print('   X_train, y_train=', X_train.shape, y_train.shape, type(X_train), type(y_train))\n",
    "print('   X_validation, y_validation=', X_validation.shape, y_validation.shape)\n",
    "print('   X_test, y_test=', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa365f60e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#M: 隨便抽張圖看看...\n",
    "i=3\n",
    "img = X_train[i].reshape((200,310))\n",
    "fig = plt.figure(figsize=(19,10))\n",
    "plt.tight_layout()\n",
    "plt.pcolormesh(img, cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vvvvv 將 AlexNet 換成 InceptionV3 Model vvvvv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, LearningRateScheduler\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop, Adam, Nadam #M: 用 Adam, Nadam 沒用.\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping\n",
    "import keras.backend as K\n",
    "### config for multi-GPU ###\n",
    "from keras.utils import multi_gpu_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.set_image_data_format('channels_first')\n",
    "model = InceptionV3(include_top=False, weights=None, input_shape=(1,200,310), pooling='avg')\n",
    "\n",
    "input_tensor = model.input\n",
    "# build top\n",
    "x = model.output\n",
    "#M: 多加一層 128 dense layer\n",
    "x = Dropout(.5)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(.5)(x)\n",
    "x = Dense(output_dim, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=input_tensor, outputs=x)\n",
    "\n",
    "### config for multi-GPU ###\n",
    "# model.compile(optimizer=Nadam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "parallel_model = multi_gpu_model(model, gpus=4)\n",
    "parallel_model.compile(optimizer=Nadam(), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 1, 200, 310)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 99, 154)  288         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 99, 154)  96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 99, 154)  0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 97, 152)  9216        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 97, 152)  96          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 97, 152)  0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 64, 97, 152)  18432       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 64, 97, 152)  192         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 64, 97, 152)  0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 64, 48, 75)   0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 80, 48, 75)   5120        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 80, 48, 75)   240         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 80, 48, 75)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 192, 46, 73)  138240      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 192, 46, 73)  576         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 192, 46, 73)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 192, 22, 36)  0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 64, 22, 36)   12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 64, 22, 36)   192         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 64, 22, 36)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 48, 22, 36)   9216        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 96, 22, 36)   55296       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 48, 22, 36)   144         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 96, 22, 36)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 48, 22, 36)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 96, 22, 36)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 192, 22, 36)  0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 22, 36)   12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 64, 22, 36)   76800       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 96, 22, 36)   82944       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 22, 36)   6144        average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 64, 22, 36)   192         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 64, 22, 36)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 96, 22, 36)   288         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 32, 22, 36)   96          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 64, 22, 36)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 64, 22, 36)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 96, 22, 36)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 32, 22, 36)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 256, 22, 36)  0           activation_6[0][0]               \n",
      "                                                                 activation_8[0][0]               \n",
      "                                                                 activation_11[0][0]              \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 64, 22, 36)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 64, 22, 36)   192         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 64, 22, 36)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 48, 22, 36)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 96, 22, 36)   55296       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 48, 22, 36)   144         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 96, 22, 36)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 48, 22, 36)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 96, 22, 36)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 256, 22, 36)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 64, 22, 36)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 64, 22, 36)   76800       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 96, 22, 36)   82944       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 64, 22, 36)   16384       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 64, 22, 36)   192         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 64, 22, 36)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 96, 22, 36)   288         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 64, 22, 36)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 64, 22, 36)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 64, 22, 36)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 96, 22, 36)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 64, 22, 36)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 288, 22, 36)  0           activation_13[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 64, 22, 36)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 64, 22, 36)   192         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 64, 22, 36)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 48, 22, 36)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 96, 22, 36)   55296       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 48, 22, 36)   144         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 96, 22, 36)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 48, 22, 36)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 96, 22, 36)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 288, 22, 36)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 64, 22, 36)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 64, 22, 36)   76800       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 96, 22, 36)   82944       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 64, 22, 36)   18432       average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 64, 22, 36)   192         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 64, 22, 36)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 96, 22, 36)   288         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 64, 22, 36)   192         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 64, 22, 36)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 64, 22, 36)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 96, 22, 36)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 64, 22, 36)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 288, 22, 36)  0           activation_20[0][0]              \n",
      "                                                                 activation_22[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "                                                                 activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 64, 22, 36)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 64, 22, 36)   192         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 64, 22, 36)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 96, 22, 36)   55296       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 96, 22, 36)   288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 96, 22, 36)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 384, 10, 17)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 96, 10, 17)   82944       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 384, 10, 17)  1152        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 96, 10, 17)   288         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 384, 10, 17)  0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 96, 10, 17)   0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 288, 10, 17)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 768, 10, 17)  0           activation_27[0][0]              \n",
      "                                                                 activation_30[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 128, 10, 17)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 128, 10, 17)  384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 128, 10, 17)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 128, 10, 17)  114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 128, 10, 17)  384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 128, 10, 17)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 128, 10, 17)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 128, 10, 17)  114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 128, 10, 17)  384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 128, 10, 17)  384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 128, 10, 17)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 128, 10, 17)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 128, 10, 17)  114688      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 128, 10, 17)  114688      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 128, 10, 17)  384         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 128, 10, 17)  384         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 128, 10, 17)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 128, 10, 17)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 768, 10, 17)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 192, 10, 17)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 192, 10, 17)  172032      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 192, 10, 17)  172032      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 192, 10, 17)  147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 192, 10, 17)  576         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 192, 10, 17)  576         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 192, 10, 17)  576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 192, 10, 17)  576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 192, 10, 17)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 192, 10, 17)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 192, 10, 17)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 192, 10, 17)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 768, 10, 17)  0           activation_31[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "                                                                 activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 160, 10, 17)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 160, 10, 17)  480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 160, 10, 17)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 160, 10, 17)  179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 160, 10, 17)  480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 160, 10, 17)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 160, 10, 17)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 160, 10, 17)  179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 160, 10, 17)  480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 160, 10, 17)  480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 160, 10, 17)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 160, 10, 17)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 160, 10, 17)  179200      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 160, 10, 17)  179200      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 160, 10, 17)  480         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 160, 10, 17)  480         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 160, 10, 17)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 160, 10, 17)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 768, 10, 17)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 192, 10, 17)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 192, 10, 17)  215040      activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 192, 10, 17)  215040      activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 192, 10, 17)  147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 192, 10, 17)  576         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 192, 10, 17)  576         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 192, 10, 17)  576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 192, 10, 17)  576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 192, 10, 17)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 192, 10, 17)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 192, 10, 17)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 192, 10, 17)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 768, 10, 17)  0           activation_41[0][0]              \n",
      "                                                                 activation_44[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "                                                                 activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 160, 10, 17)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 160, 10, 17)  480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 160, 10, 17)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 160, 10, 17)  179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 160, 10, 17)  480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 160, 10, 17)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 160, 10, 17)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 160, 10, 17)  179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 160, 10, 17)  480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 160, 10, 17)  480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 160, 10, 17)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 160, 10, 17)  0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 160, 10, 17)  179200      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 160, 10, 17)  179200      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 160, 10, 17)  480         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 160, 10, 17)  480         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 160, 10, 17)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 160, 10, 17)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 768, 10, 17)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 192, 10, 17)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 192, 10, 17)  215040      activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 192, 10, 17)  215040      activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 192, 10, 17)  147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 192, 10, 17)  576         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 192, 10, 17)  576         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 192, 10, 17)  576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 192, 10, 17)  576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 192, 10, 17)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 192, 10, 17)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 192, 10, 17)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 192, 10, 17)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 768, 10, 17)  0           activation_51[0][0]              \n",
      "                                                                 activation_54[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "                                                                 activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 192, 10, 17)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 192, 10, 17)  576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 192, 10, 17)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 192, 10, 17)  258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 192, 10, 17)  576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 192, 10, 17)  0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 192, 10, 17)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 192, 10, 17)  258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 192, 10, 17)  576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 192, 10, 17)  576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 192, 10, 17)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 192, 10, 17)  0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 192, 10, 17)  258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 192, 10, 17)  258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 192, 10, 17)  576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 192, 10, 17)  576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 192, 10, 17)  0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 192, 10, 17)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 768, 10, 17)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 192, 10, 17)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 192, 10, 17)  258048      activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 192, 10, 17)  258048      activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 192, 10, 17)  147456      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 192, 10, 17)  576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 192, 10, 17)  576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 192, 10, 17)  576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 192, 10, 17)  576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 192, 10, 17)  0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 192, 10, 17)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 192, 10, 17)  0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 192, 10, 17)  0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 768, 10, 17)  0           activation_61[0][0]              \n",
      "                                                                 activation_64[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "                                                                 activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 192, 10, 17)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 192, 10, 17)  576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 192, 10, 17)  0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 192, 10, 17)  258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 192, 10, 17)  576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 192, 10, 17)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 192, 10, 17)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 192, 10, 17)  258048      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 192, 10, 17)  576         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 192, 10, 17)  576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 192, 10, 17)  0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 192, 10, 17)  0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 320, 4, 8)    552960      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 192, 4, 8)    331776      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 320, 4, 8)    960         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 192, 4, 8)    576         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 320, 4, 8)    0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 192, 4, 8)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 768, 4, 8)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 1280, 4, 8)   0           activation_72[0][0]              \n",
      "                                                                 activation_76[0][0]              \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 448, 4, 8)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 448, 4, 8)    1344        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 448, 4, 8)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 384, 4, 8)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 384, 4, 8)    1548288     activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 384, 4, 8)    1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 384, 4, 8)    1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 384, 4, 8)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 384, 4, 8)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 384, 4, 8)    442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 384, 4, 8)    442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 384, 4, 8)    442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 384, 4, 8)    442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 1280, 4, 8)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 320, 4, 8)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 384, 4, 8)    1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 384, 4, 8)    1152        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 384, 4, 8)    1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 384, 4, 8)    1152        conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 192, 4, 8)    245760      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 320, 4, 8)    960         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 384, 4, 8)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 384, 4, 8)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 384, 4, 8)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 384, 4, 8)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 192, 4, 8)    576         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 320, 4, 8)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 768, 4, 8)    0           activation_79[0][0]              \n",
      "                                                                 activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 768, 4, 8)    0           activation_83[0][0]              \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 192, 4, 8)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 2048, 4, 8)   0           activation_77[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 448, 4, 8)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 448, 4, 8)    1344        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 448, 4, 8)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 384, 4, 8)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 384, 4, 8)    1548288     activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 384, 4, 8)    1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 384, 4, 8)    1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 384, 4, 8)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 384, 4, 8)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 384, 4, 8)    442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 384, 4, 8)    442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 384, 4, 8)    442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 384, 4, 8)    442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, 2048, 4, 8)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 320, 4, 8)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 384, 4, 8)    1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 384, 4, 8)    1152        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 384, 4, 8)    1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 384, 4, 8)    1152        conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 192, 4, 8)    393216      average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 320, 4, 8)    960         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 384, 4, 8)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 384, 4, 8)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 384, 4, 8)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 384, 4, 8)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 192, 4, 8)    576         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 320, 4, 8)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 768, 4, 8)    0           activation_88[0][0]              \n",
      "                                                                 activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 768, 4, 8)    0           activation_92[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 192, 4, 8)    0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 2048, 4, 8)   0           activation_86[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 2048)         0           global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          262272      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 128)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 123)          15867       dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 22,080,347\n",
      "Trainable params: 22,045,915\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ^^^^^ 將 AlexNet 換成 InceptionV3 Model ^^^^^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epochs = 20000 # number of epochs, should be high, the end of the learning process is controled by early stoping\n",
    "es_patience = 150 # patience for early stoping \n",
    "batchSize = 400 # batch size for mini-batch training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr decay schedule\n",
    "def lr_schedule(epoch):\n",
    "    \"\"\"Learning Rate Schedule\n",
    "    Learning rate is scheduled to be reduced after 80, 120epochs.\n",
    "    Called automatically every epoch as part of callbacks during training.\n",
    "    # Arguments\n",
    "        epoch (int): The number of epochs\n",
    "    # Returns\n",
    "        lr (float32): learning rate\n",
    "    \"\"\"\n",
    "\n",
    "    lr = 1e-3\n",
    "    decay = int(epoch / 100)\n",
    "    if decay != 0:\n",
    "        lr /= (10 ** decay)\n",
    "    print('Learning rate = {}, decay = {}'.format(lr, decay))\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call backs\n",
    "if os.path.exists('./modelWeights/') is False:\n",
    "    os.mkdir('./modelWeights/') #M:\n",
    "\n",
    "### config for multi-GPU ###\n",
    "checkpointer = ModelCheckpoint(filepath='./modelWeights/weights.{epoch:06d}-{val_loss:.2f}.hdf5', save_weights_only=True, verbose=1, save_best_only=True)\n",
    "# checkpointer = ModelCheckpoint(filepath='./modelWeights/weights.h5', verbose=1, save_best_only=True)\n",
    "lr = LearningRateScheduler(lr_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model and compile it, we use RMSprop here, other optimizer algorithm should be tested\n",
    "# execfile(modelPath)\n",
    "# model.compile(loss='categorical_crossentropy', optimizer='rmsprop')#, metrics=[\"accuracy\"])\n",
    "\n",
    "# print the model\n",
    "# print(\"The following model is used: \")\n",
    "# for layer in model.layers:\n",
    "#     print(\"{} output shape: {}\".format(layer.name, layer.output_shape))\n",
    "\n",
    "# load pretrained model if it is set\n",
    "# if preTrainedModelWeightsPath is not None:\n",
    "#     model.load_weights(preTrainedModelWeightsPath)\n",
    "#     print(\"Reloaded weights from: {}\".format(preTrainedModelWeightsPath))\n",
    "\n",
    "# define callback functions\n",
    "# mapcallback = MapCallback()\n",
    "\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', patience = es_patience) # early stoping\n",
    "\n",
    "# save best models based on accuracy, loss and MAP metrics\n",
    "#bestModelFilePath_val_map = './modelWeights/best_val_map_{}_{}.hdf5'.format(output_dim, datetime.datetime.now().strftime('%Y-%m-%d-%M-%S'))\n",
    "#bestModelFilePath_val_acc = './modelWeights/best_val_acc_{}_{}.hdf5'.format(output_dim, datetime.datetime.now().strftime('%Y-%m-%d-%M-%S'))\n",
    "#bestModelFilePath_val_loss = './modelWeights/best_val_loss_{}_{}.hdf5'.format(output_dim, datetime.datetime.now().strftime('%Y-%m-%d-%M-%S'))\n",
    "\n",
    "\n",
    "# bestModelFilePath_val_acc = './modelWeights/best_val_acc_{}.hdf5'.format(output_dim)\n",
    "# bestModelFilePath_val_loss = './modelWeights/best_val_loss_{}.hdf5'.format(output_dim)\n",
    "# bestModelFilePath_val_map = './modelWeights/best_val_map_{}.hdf5'.format(output_dim)\n",
    "# checkpointer_val_acc = ModelCheckpoint(filepath = bestModelFilePath_val_acc, verbose = 1, monitor = 'val_acc', save_best_only = True)\n",
    "# checkpointer_val_loss = ModelCheckpoint(filepath = bestModelFilePath_val_loss, verbose = 1, monitor = 'val_loss', save_best_only = True)\n",
    "# checkpointer_val_map = ModelCheckpoint(filepath = bestModelFilePath_val_map, verbose = 1, monitor = 'val_map', mode = 'max', save_best_only = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14829 samples, validate on 1648 samples\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 1/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 4.3790 - acc: 0.1144\n",
      "Epoch 00001: val_loss improved from inf to 15.75843, saving model to ./modelWeights/weights.000001-15.76.hdf5\n",
      "14829/14829 [==============================] - 47s 3ms/step - loss: 4.3791 - acc: 0.1143 - val_loss: 15.7584 - val_acc: 0.0133\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 2/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 3.9049 - acc: 0.1607\n",
      "Epoch 00002: val_loss improved from 15.75843 to 5.89332, saving model to ./modelWeights/weights.000002-5.89.hdf5\n",
      "14829/14829 [==============================] - 30s 2ms/step - loss: 3.9049 - acc: 0.1608 - val_loss: 5.8933 - val_acc: 0.0394\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 3/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 3.6166 - acc: 0.2017\n",
      "Epoch 00003: val_loss improved from 5.89332 to 5.85381, saving model to ./modelWeights/weights.000003-5.85.hdf5\n",
      "14829/14829 [==============================] - 29s 2ms/step - loss: 3.6177 - acc: 0.2014 - val_loss: 5.8538 - val_acc: 0.0868\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 4/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 3.3502 - acc: 0.2364\n",
      "Epoch 00004: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 3.3506 - acc: 0.2364 - val_loss: 6.3566 - val_acc: 0.0133\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 5/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 3.0999 - acc: 0.2775\n",
      "Epoch 00005: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 3.1006 - acc: 0.2776 - val_loss: 15.4046 - val_acc: 0.0164\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 6/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 3.2292 - acc: 0.2611\n",
      "Epoch 00006: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 3.2302 - acc: 0.2608 - val_loss: 9.3668 - val_acc: 0.0710\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 7/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 2.9541 - acc: 0.3022\n",
      "Epoch 00007: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 2.9544 - acc: 0.3022 - val_loss: 15.8442 - val_acc: 0.0170\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 8/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 2.7554 - acc: 0.3366\n",
      "Epoch 00008: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 2.7574 - acc: 0.3363 - val_loss: 12.6379 - val_acc: 0.0127\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 9/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 2.5040 - acc: 0.3900\n",
      "Epoch 00009: val_loss improved from 5.85381 to 4.56693, saving model to ./modelWeights/weights.000009-4.57.hdf5\n",
      "14829/14829 [==============================] - 30s 2ms/step - loss: 2.5038 - acc: 0.3902 - val_loss: 4.5669 - val_acc: 0.1098\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 10/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 2.2930 - acc: 0.4401\n",
      "Epoch 00010: val_loss did not improve\n",
      "14829/14829 [==============================] - 27s 2ms/step - loss: 2.2953 - acc: 0.4397 - val_loss: 8.6560 - val_acc: 0.1092\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 11/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 2.2782 - acc: 0.4451\n",
      "Epoch 00011: val_loss did not improve\n",
      "14829/14829 [==============================] - 27s 2ms/step - loss: 2.2785 - acc: 0.4452 - val_loss: 9.3667 - val_acc: 0.0892\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 12/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 2.1204 - acc: 0.4764\n",
      "Epoch 00012: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 2.1210 - acc: 0.4764 - val_loss: 5.9598 - val_acc: 0.1984\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 13/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 1.9215 - acc: 0.5161\n",
      "Epoch 00013: val_loss did not improve\n",
      "14829/14829 [==============================] - 27s 2ms/step - loss: 1.9220 - acc: 0.5160 - val_loss: 6.0483 - val_acc: 0.1450\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 14/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 1.8752 - acc: 0.5311\n",
      "Epoch 00014: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 1.8770 - acc: 0.5309 - val_loss: 6.2968 - val_acc: 0.1468\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 15/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 1.8394 - acc: 0.5409\n",
      "Epoch 00015: val_loss did not improve\n",
      "14829/14829 [==============================] - 27s 2ms/step - loss: 1.8405 - acc: 0.5408 - val_loss: 5.0208 - val_acc: 0.2348\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 16/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 1.5439 - acc: 0.6115\n",
      "Epoch 00016: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 1.5454 - acc: 0.6111 - val_loss: 11.0256 - val_acc: 0.0922\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 17/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 1.5660 - acc: 0.6080\n",
      "Epoch 00017: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 1.5693 - acc: 0.6074 - val_loss: 10.8597 - val_acc: 0.0625\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 18/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 1.6313 - acc: 0.5932\n",
      "Epoch 00018: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 1.6310 - acc: 0.5932 - val_loss: 10.5534 - val_acc: 0.0734\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 19/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 1.3417 - acc: 0.6580\n",
      "Epoch 00019: val_loss did not improve\n",
      "14829/14829 [==============================] - 27s 2ms/step - loss: 1.3427 - acc: 0.6578 - val_loss: 6.5706 - val_acc: 0.1311\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 20/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 1.3929 - acc: 0.6555\n",
      "Epoch 00020: val_loss did not improve\n",
      "14829/14829 [==============================] - 27s 2ms/step - loss: 1.3941 - acc: 0.6554 - val_loss: 9.5472 - val_acc: 0.1723\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 21/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 1.2379 - acc: 0.6818\n",
      "Epoch 00021: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 1.2401 - acc: 0.6814 - val_loss: 10.6202 - val_acc: 0.0831\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 22/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 1.2550 - acc: 0.6839\n",
      "Epoch 00022: val_loss improved from 4.56693 to 3.25602, saving model to ./modelWeights/weights.000022-3.26.hdf5\n",
      "14829/14829 [==============================] - 29s 2ms/step - loss: 1.2551 - acc: 0.6838 - val_loss: 3.2560 - val_acc: 0.3823\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 23/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 1.0612 - acc: 0.7266\n",
      "Epoch 00023: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 1.0628 - acc: 0.7262 - val_loss: 10.7613 - val_acc: 0.1086\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 24/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 1.1063 - acc: 0.7149\n",
      "Epoch 00024: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 1.1078 - acc: 0.7147 - val_loss: 5.9588 - val_acc: 0.2894\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 25/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.9995 - acc: 0.7399\n",
      "Epoch 00025: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 1.0018 - acc: 0.7395 - val_loss: 8.3058 - val_acc: 0.1347\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 26/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 1.2299 - acc: 0.6911\n",
      "Epoch 00026: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 1.2321 - acc: 0.6907 - val_loss: 10.0201 - val_acc: 0.1001\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 27/20000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14800/14829 [============================>.] - ETA: 0s - loss: 1.0018 - acc: 0.7411\n",
      "Epoch 00027: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 1.0033 - acc: 0.7408 - val_loss: 5.7810 - val_acc: 0.1717\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 28/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.8976 - acc: 0.7668\n",
      "Epoch 00028: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.8978 - acc: 0.7667 - val_loss: 7.3951 - val_acc: 0.2846\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 29/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.6958 - acc: 0.8155\n",
      "Epoch 00029: val_loss did not improve\n",
      "14829/14829 [==============================] - 27s 2ms/step - loss: 0.6984 - acc: 0.8150 - val_loss: 6.8093 - val_acc: 0.1110\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 30/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.8018 - acc: 0.7913\n",
      "Epoch 00030: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.8039 - acc: 0.7911 - val_loss: 5.2633 - val_acc: 0.3216\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 31/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.7407 - acc: 0.8037\n",
      "Epoch 00031: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.7428 - acc: 0.8034 - val_loss: 4.6986 - val_acc: 0.3034\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 32/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.7157 - acc: 0.8106\n",
      "Epoch 00032: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.7165 - acc: 0.8104 - val_loss: 3.7387 - val_acc: 0.3701\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 33/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.6011 - acc: 0.8401\n",
      "Epoch 00033: val_loss improved from 3.25602 to 2.98698, saving model to ./modelWeights/weights.000033-2.99.hdf5\n",
      "14829/14829 [==============================] - 29s 2ms/step - loss: 0.6024 - acc: 0.8397 - val_loss: 2.9870 - val_acc: 0.4436\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 34/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.5948 - acc: 0.8409\n",
      "Epoch 00034: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.5956 - acc: 0.8409 - val_loss: 6.0598 - val_acc: 0.3040\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 35/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.6033 - acc: 0.8426\n",
      "Epoch 00035: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.6063 - acc: 0.8419 - val_loss: 7.7321 - val_acc: 0.1487\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 36/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.8102 - acc: 0.7968\n",
      "Epoch 00036: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.8108 - acc: 0.7965 - val_loss: 10.6318 - val_acc: 0.1323\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 37/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.6036 - acc: 0.8393\n",
      "Epoch 00037: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.6050 - acc: 0.8390 - val_loss: 6.4785 - val_acc: 0.2803\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 38/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.5411 - acc: 0.8572\n",
      "Epoch 00038: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.5432 - acc: 0.8568 - val_loss: 8.1457 - val_acc: 0.2676\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 39/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.5608 - acc: 0.8526\n",
      "Epoch 00039: val_loss improved from 2.98698 to 2.52242, saving model to ./modelWeights/weights.000039-2.52.hdf5\n",
      "14829/14829 [==============================] - 29s 2ms/step - loss: 0.5615 - acc: 0.8524 - val_loss: 2.5224 - val_acc: 0.5249\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 40/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.3879 - acc: 0.8927\n",
      "Epoch 00040: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.3910 - acc: 0.8922 - val_loss: 5.5792 - val_acc: 0.2749\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 41/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.5887 - acc: 0.8466\n",
      "Epoch 00041: val_loss did not improve\n",
      "14829/14829 [==============================] - 27s 2ms/step - loss: 0.5910 - acc: 0.8460 - val_loss: 5.7954 - val_acc: 0.2779\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 42/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.4896 - acc: 0.8731\n",
      "Epoch 00042: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.4909 - acc: 0.8729 - val_loss: 3.6610 - val_acc: 0.4302\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 43/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.4243 - acc: 0.8850\n",
      "Epoch 00043: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.4257 - acc: 0.8846 - val_loss: 8.2643 - val_acc: 0.2445\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 44/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.4119 - acc: 0.8916\n",
      "Epoch 00044: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.4127 - acc: 0.8915 - val_loss: 2.7502 - val_acc: 0.5127\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 45/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.3063 - acc: 0.9174\n",
      "Epoch 00045: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.3079 - acc: 0.9171 - val_loss: 6.1860 - val_acc: 0.2251\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 46/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.4227 - acc: 0.8878\n",
      "Epoch 00046: val_loss did not improve\n",
      "14829/14829 [==============================] - 27s 2ms/step - loss: 0.4240 - acc: 0.8875 - val_loss: 3.7515 - val_acc: 0.4102\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 47/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.4241 - acc: 0.8878\n",
      "Epoch 00047: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.4250 - acc: 0.8877 - val_loss: 3.6997 - val_acc: 0.4430\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 48/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.2873 - acc: 0.9211\n",
      "Epoch 00048: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.2890 - acc: 0.9207 - val_loss: 2.8110 - val_acc: 0.5303\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 49/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.2939 - acc: 0.9182\n",
      "Epoch 00049: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.2971 - acc: 0.9175 - val_loss: 7.3107 - val_acc: 0.2415\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 50/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.4937 - acc: 0.8775\n",
      "Epoch 00050: val_loss improved from 2.52242 to 2.37043, saving model to ./modelWeights/weights.000050-2.37.hdf5\n",
      "14829/14829 [==============================] - 29s 2ms/step - loss: 0.4941 - acc: 0.8774 - val_loss: 2.3704 - val_acc: 0.5947\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 51/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.2387 - acc: 0.9330\n",
      "Epoch 00051: val_loss improved from 2.37043 to 2.21144, saving model to ./modelWeights/weights.000051-2.21.hdf5\n",
      "14829/14829 [==============================] - 29s 2ms/step - loss: 0.2404 - acc: 0.9326 - val_loss: 2.2114 - val_acc: 0.6244\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 52/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.2206 - acc: 0.9395\n",
      "Epoch 00052: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.2221 - acc: 0.9390 - val_loss: 3.5627 - val_acc: 0.4897\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 53/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.2928 - acc: 0.9237\n",
      "Epoch 00053: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.2965 - acc: 0.9231 - val_loss: 8.1038 - val_acc: 0.1760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 54/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.4759 - acc: 0.8811\n",
      "Epoch 00054: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.4770 - acc: 0.8806 - val_loss: 4.1273 - val_acc: 0.4326\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 55/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.2836 - acc: 0.9239\n",
      "Epoch 00055: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.2864 - acc: 0.9235 - val_loss: 3.8607 - val_acc: 0.4873\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 56/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.2987 - acc: 0.9211\n",
      "Epoch 00056: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.3003 - acc: 0.9207 - val_loss: 3.1459 - val_acc: 0.5024\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 57/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.2793 - acc: 0.9278\n",
      "Epoch 00057: val_loss improved from 2.21144 to 1.93151, saving model to ./modelWeights/weights.000057-1.93.hdf5\n",
      "14829/14829 [==============================] - 29s 2ms/step - loss: 0.2795 - acc: 0.9277 - val_loss: 1.9315 - val_acc: 0.6693\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 58/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.1658 - acc: 0.9541\n",
      "Epoch 00058: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.1666 - acc: 0.9537 - val_loss: 3.8563 - val_acc: 0.5400\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 59/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.2144 - acc: 0.9407\n",
      "Epoch 00059: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.2169 - acc: 0.9400 - val_loss: 10.8515 - val_acc: 0.1299\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 60/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.4649 - acc: 0.8885\n",
      "Epoch 00060: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.4663 - acc: 0.8883 - val_loss: 2.8473 - val_acc: 0.5255\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 61/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.2609 - acc: 0.9302\n",
      "Epoch 00061: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.2634 - acc: 0.9299 - val_loss: 4.3213 - val_acc: 0.3920\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 62/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.2465 - acc: 0.9331\n",
      "Epoch 00062: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.2477 - acc: 0.9328 - val_loss: 3.2222 - val_acc: 0.5212\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 63/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.2472 - acc: 0.9359\n",
      "Epoch 00063: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.2493 - acc: 0.9355 - val_loss: 5.1589 - val_acc: 0.3653\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 64/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.3246 - acc: 0.9173\n",
      "Epoch 00064: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.3264 - acc: 0.9167 - val_loss: 4.8045 - val_acc: 0.3070\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 65/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.3834 - acc: 0.9024\n",
      "Epoch 00065: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.3852 - acc: 0.9019 - val_loss: 6.0090 - val_acc: 0.4053\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 66/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.2624 - acc: 0.9301\n",
      "Epoch 00066: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.2635 - acc: 0.9299 - val_loss: 5.6746 - val_acc: 0.3871\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 67/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.2174 - acc: 0.9426\n",
      "Epoch 00067: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.2213 - acc: 0.9422 - val_loss: 4.4115 - val_acc: 0.4399\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 68/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.2606 - acc: 0.9315\n",
      "Epoch 00068: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.2628 - acc: 0.9309 - val_loss: 2.7247 - val_acc: 0.5728\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 69/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.2177 - acc: 0.9432\n",
      "Epoch 00069: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.2189 - acc: 0.9429 - val_loss: 4.6162 - val_acc: 0.4072\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 70/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.1765 - acc: 0.9510\n",
      "Epoch 00070: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.1783 - acc: 0.9504 - val_loss: 3.2746 - val_acc: 0.5255\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 71/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.2197 - acc: 0.9418\n",
      "Epoch 00071: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.2214 - acc: 0.9414 - val_loss: 3.5087 - val_acc: 0.5146\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 72/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.2799 - acc: 0.9274\n",
      "Epoch 00072: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.2826 - acc: 0.9269 - val_loss: 3.1959 - val_acc: 0.5273\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 73/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.2376 - acc: 0.9380\n",
      "Epoch 00073: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.2391 - acc: 0.9374 - val_loss: 3.0376 - val_acc: 0.5261\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 74/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.2085 - acc: 0.9435\n",
      "Epoch 00074: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.2115 - acc: 0.9431 - val_loss: 4.1700 - val_acc: 0.4326\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 75/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.2403 - acc: 0.9378\n",
      "Epoch 00075: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.2415 - acc: 0.9374 - val_loss: 2.4549 - val_acc: 0.5856\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 76/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.1611 - acc: 0.9566\n",
      "Epoch 00076: val_loss improved from 1.93151 to 1.68485, saving model to ./modelWeights/weights.000076-1.68.hdf5\n",
      "14829/14829 [==============================] - 29s 2ms/step - loss: 0.1626 - acc: 0.9562 - val_loss: 1.6849 - val_acc: 0.6984\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 77/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.1781 - acc: 0.9526\n",
      "Epoch 00077: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.1813 - acc: 0.9521 - val_loss: 2.6916 - val_acc: 0.6098\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 78/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.1948 - acc: 0.9495\n",
      "Epoch 00078: val_loss improved from 1.68485 to 1.59075, saving model to ./modelWeights/weights.000078-1.59.hdf5\n",
      "14829/14829 [==============================] - 29s 2ms/step - loss: 0.1958 - acc: 0.9492 - val_loss: 1.5907 - val_acc: 0.7148\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 79/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.1304 - acc: 0.9617\n",
      "Epoch 00079: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.1337 - acc: 0.9611 - val_loss: 8.1841 - val_acc: 0.2573\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 80/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.2753 - acc: 0.9307\n",
      "Epoch 00080: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.2773 - acc: 0.9305 - val_loss: 2.9567 - val_acc: 0.5479\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 81/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.1544 - acc: 0.9591\n",
      "Epoch 00081: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.1559 - acc: 0.9587 - val_loss: 2.6607 - val_acc: 0.5959\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 82/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.1316 - acc: 0.9643\n",
      "Epoch 00082: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.1344 - acc: 0.9638 - val_loss: 4.8814 - val_acc: 0.3792\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 83/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.2297 - acc: 0.9434\n",
      "Epoch 00083: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.2307 - acc: 0.9430 - val_loss: 3.2594 - val_acc: 0.5552\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 84/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.1785 - acc: 0.9543\n",
      "Epoch 00084: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.1811 - acc: 0.9537 - val_loss: 3.2653 - val_acc: 0.5479\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 85/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.2303 - acc: 0.9381\n",
      "Epoch 00085: val_loss improved from 1.59075 to 1.50623, saving model to ./modelWeights/weights.000085-1.51.hdf5\n",
      "14829/14829 [==============================] - 29s 2ms/step - loss: 0.2316 - acc: 0.9379 - val_loss: 1.5062 - val_acc: 0.7251\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 86/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.1286 - acc: 0.9648\n",
      "Epoch 00086: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.1300 - acc: 0.9645 - val_loss: 2.6980 - val_acc: 0.5947\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 87/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.1297 - acc: 0.9627\n",
      "Epoch 00087: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.1319 - acc: 0.9622 - val_loss: 3.7035 - val_acc: 0.4320\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 88/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.2501 - acc: 0.9368\n",
      "Epoch 00088: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.2520 - acc: 0.9364 - val_loss: 4.1589 - val_acc: 0.4545\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 89/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.2077 - acc: 0.9464\n",
      "Epoch 00089: val_loss did not improve\n",
      "14829/14829 [==============================] - 27s 2ms/step - loss: 0.2105 - acc: 0.9457 - val_loss: 5.5139 - val_acc: 0.3883\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 90/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.1999 - acc: 0.9467\n",
      "Epoch 00090: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.2014 - acc: 0.9463 - val_loss: 1.6550 - val_acc: 0.6984\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 91/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.1334 - acc: 0.9621\n",
      "Epoch 00091: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.1363 - acc: 0.9616 - val_loss: 2.4475 - val_acc: 0.6274\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 92/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.1876 - acc: 0.9481\n",
      "Epoch 00092: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.1900 - acc: 0.9475 - val_loss: 3.4596 - val_acc: 0.4842\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 93/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.1650 - acc: 0.9547\n",
      "Epoch 00093: val_loss improved from 1.50623 to 1.11637, saving model to ./modelWeights/weights.000093-1.12.hdf5\n",
      "14829/14829 [==============================] - 29s 2ms/step - loss: 0.1670 - acc: 0.9544 - val_loss: 1.1164 - val_acc: 0.7943\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 94/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.1236 - acc: 0.9653\n",
      "Epoch 00094: val_loss did not improve\n",
      "14829/14829 [==============================] - 27s 2ms/step - loss: 0.1258 - acc: 0.9647 - val_loss: 5.2584 - val_acc: 0.4733\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 95/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.1568 - acc: 0.9582\n",
      "Epoch 00095: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.1581 - acc: 0.9577 - val_loss: 5.3524 - val_acc: 0.3732\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 96/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.1966 - acc: 0.9466\n",
      "Epoch 00096: val_loss did not improve\n",
      "14829/14829 [==============================] - 27s 2ms/step - loss: 0.1975 - acc: 0.9464 - val_loss: 1.6495 - val_acc: 0.7257\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 97/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.1453 - acc: 0.9597\n",
      "Epoch 00097: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.1471 - acc: 0.9593 - val_loss: 4.1787 - val_acc: 0.5164\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 98/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.1370 - acc: 0.9632\n",
      "Epoch 00098: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.1387 - acc: 0.9626 - val_loss: 2.2059 - val_acc: 0.6329\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 99/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.1775 - acc: 0.9527\n",
      "Epoch 00099: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.1788 - acc: 0.9523 - val_loss: 3.0213 - val_acc: 0.5680\n",
      "Learning rate = 0.001, decay = 0\n",
      "Epoch 100/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.1133 - acc: 0.9690\n",
      "Epoch 00100: val_loss did not improve\n",
      "14829/14829 [==============================] - 27s 2ms/step - loss: 0.1157 - acc: 0.9687 - val_loss: 2.8406 - val_acc: 0.5564\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 101/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.2365 - acc: 0.9444\n",
      "Epoch 00101: val_loss improved from 1.11637 to 0.85806, saving model to ./modelWeights/weights.000101-0.86.hdf5\n",
      "14829/14829 [==============================] - 29s 2ms/step - loss: 0.2389 - acc: 0.9439 - val_loss: 0.8581 - val_acc: 0.8422\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 102/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0629 - acc: 0.9825\n",
      "Epoch 00102: val_loss improved from 0.85806 to 0.74983, saving model to ./modelWeights/weights.000102-0.75.hdf5\n",
      "14829/14829 [==============================] - 29s 2ms/step - loss: 0.0646 - acc: 0.9821 - val_loss: 0.7498 - val_acc: 0.8562\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 103/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0498 - acc: 0.9863\n",
      "Epoch 00103: val_loss improved from 0.74983 to 0.72158, saving model to ./modelWeights/weights.000103-0.72.hdf5\n",
      "14829/14829 [==============================] - 29s 2ms/step - loss: 0.0531 - acc: 0.9859 - val_loss: 0.7216 - val_acc: 0.8659\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 104/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0447 - acc: 0.9890\n",
      "Epoch 00104: val_loss improved from 0.72158 to 0.69324, saving model to ./modelWeights/weights.000104-0.69.hdf5\n",
      "14829/14829 [==============================] - 30s 2ms/step - loss: 0.0468 - acc: 0.9885 - val_loss: 0.6932 - val_acc: 0.8738\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 105/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0436 - acc: 0.9884\n",
      "Epoch 00105: val_loss improved from 0.69324 to 0.67306, saving model to ./modelWeights/weights.000105-0.67.hdf5\n",
      "14829/14829 [==============================] - 29s 2ms/step - loss: 0.0453 - acc: 0.9881 - val_loss: 0.6731 - val_acc: 0.8750\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 106/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0355 - acc: 0.9907\n",
      "Epoch 00106: val_loss improved from 0.67306 to 0.66344, saving model to ./modelWeights/weights.000106-0.66.hdf5\n",
      "14829/14829 [==============================] - 29s 2ms/step - loss: 0.0362 - acc: 0.9906 - val_loss: 0.6634 - val_acc: 0.8811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 107/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0327 - acc: 0.9916\n",
      "Epoch 00107: val_loss improved from 0.66344 to 0.65909, saving model to ./modelWeights/weights.000107-0.66.hdf5\n",
      "14829/14829 [==============================] - 29s 2ms/step - loss: 0.0333 - acc: 0.9914 - val_loss: 0.6591 - val_acc: 0.8805\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 108/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0299 - acc: 0.9924\n",
      "Epoch 00108: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0331 - acc: 0.9916 - val_loss: 0.6701 - val_acc: 0.8774\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 109/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0318 - acc: 0.9924\n",
      "Epoch 00109: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0336 - acc: 0.9920 - val_loss: 0.6896 - val_acc: 0.8756\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 110/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0307 - acc: 0.9923\n",
      "Epoch 00110: val_loss did not improve\n",
      "14829/14829 [==============================] - 27s 2ms/step - loss: 0.0322 - acc: 0.9918 - val_loss: 0.6877 - val_acc: 0.8792\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 111/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0272 - acc: 0.9926\n",
      "Epoch 00111: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0285 - acc: 0.9924 - val_loss: 0.6823 - val_acc: 0.8780\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 112/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0246 - acc: 0.9941\n",
      "Epoch 00112: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0268 - acc: 0.9935 - val_loss: 0.6762 - val_acc: 0.8811\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 113/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0255 - acc: 0.9939\n",
      "Epoch 00113: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0268 - acc: 0.9937 - val_loss: 0.6847 - val_acc: 0.8829\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 114/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0219 - acc: 0.9943\n",
      "Epoch 00114: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0228 - acc: 0.9941 - val_loss: 0.6730 - val_acc: 0.8829\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 115/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0228 - acc: 0.9945\n",
      "Epoch 00115: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0232 - acc: 0.9943 - val_loss: 0.6658 - val_acc: 0.8859\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 116/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0208 - acc: 0.9947\n",
      "Epoch 00116: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0228 - acc: 0.9941 - val_loss: 0.6808 - val_acc: 0.8841\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 117/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0241 - acc: 0.9929\n",
      "Epoch 00117: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0247 - acc: 0.9928 - val_loss: 0.7064 - val_acc: 0.8799\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 118/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0233 - acc: 0.9940\n",
      "Epoch 00118: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0247 - acc: 0.9937 - val_loss: 0.7173 - val_acc: 0.8756\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 119/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0206 - acc: 0.9944\n",
      "Epoch 00119: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0229 - acc: 0.9939 - val_loss: 0.7728 - val_acc: 0.8732\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 120/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0237 - acc: 0.9941\n",
      "Epoch 00120: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0243 - acc: 0.9939 - val_loss: 0.7598 - val_acc: 0.8756\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 121/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0211 - acc: 0.9945\n",
      "Epoch 00121: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0218 - acc: 0.9943 - val_loss: 0.7325 - val_acc: 0.8786\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 122/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0188 - acc: 0.9951\n",
      "Epoch 00122: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0204 - acc: 0.9947 - val_loss: 0.7071 - val_acc: 0.8786\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 123/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0192 - acc: 0.9953\n",
      "Epoch 00123: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0218 - acc: 0.9947 - val_loss: 0.7218 - val_acc: 0.8799\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 124/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0219 - acc: 0.9934\n",
      "Epoch 00124: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0237 - acc: 0.9931 - val_loss: 0.7374 - val_acc: 0.8750\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 125/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0204 - acc: 0.9948\n",
      "Epoch 00125: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0210 - acc: 0.9945 - val_loss: 0.7288 - val_acc: 0.8768\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 126/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0183 - acc: 0.9951\n",
      "Epoch 00126: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0199 - acc: 0.9949 - val_loss: 0.7191 - val_acc: 0.8774\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 127/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0251 - acc: 0.9934\n",
      "Epoch 00127: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0282 - acc: 0.9929 - val_loss: 0.7132 - val_acc: 0.8762\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 128/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0229 - acc: 0.9941\n",
      "Epoch 00128: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0242 - acc: 0.9937 - val_loss: 0.7187 - val_acc: 0.8823\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 129/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0216 - acc: 0.9936\n",
      "Epoch 00129: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0229 - acc: 0.9933 - val_loss: 0.7089 - val_acc: 0.8871\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 130/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0221 - acc: 0.9942\n",
      "Epoch 00130: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0246 - acc: 0.9937 - val_loss: 0.7001 - val_acc: 0.8811\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 131/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0193 - acc: 0.9957\n",
      "Epoch 00131: val_loss did not improve\n",
      "14829/14829 [==============================] - 27s 2ms/step - loss: 0.0212 - acc: 0.9955 - val_loss: 0.6962 - val_acc: 0.8829\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 132/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0196 - acc: 0.9947\n",
      "Epoch 00132: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0209 - acc: 0.9944 - val_loss: 0.6938 - val_acc: 0.8805\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 133/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0200 - acc: 0.9943\n",
      "Epoch 00133: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0206 - acc: 0.9940 - val_loss: 0.6871 - val_acc: 0.8841\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 134/20000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0180 - acc: 0.9955\n",
      "Epoch 00134: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0185 - acc: 0.9954 - val_loss: 0.6835 - val_acc: 0.8853\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 135/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0171 - acc: 0.9956\n",
      "Epoch 00135: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0177 - acc: 0.9955 - val_loss: 0.6843 - val_acc: 0.8865\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 136/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0153 - acc: 0.9956\n",
      "Epoch 00136: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0166 - acc: 0.9953 - val_loss: 0.7109 - val_acc: 0.8829\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 137/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0191 - acc: 0.9947\n",
      "Epoch 00137: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0200 - acc: 0.9945 - val_loss: 0.7213 - val_acc: 0.8774\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 138/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0157 - acc: 0.9963\n",
      "Epoch 00138: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0164 - acc: 0.9961 - val_loss: 0.6991 - val_acc: 0.8877\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 139/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0181 - acc: 0.9949\n",
      "Epoch 00139: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0192 - acc: 0.9945 - val_loss: 0.7400 - val_acc: 0.8756\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 140/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0185 - acc: 0.9948\n",
      "Epoch 00140: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0190 - acc: 0.9947 - val_loss: 0.6859 - val_acc: 0.8847\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 141/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0175 - acc: 0.9956\n",
      "Epoch 00141: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0205 - acc: 0.9951 - val_loss: 0.7092 - val_acc: 0.8817\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 142/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0223 - acc: 0.9933\n",
      "Epoch 00142: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0240 - acc: 0.9930 - val_loss: 0.7665 - val_acc: 0.8799\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 143/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0214 - acc: 0.9939\n",
      "Epoch 00143: val_loss did not improve\n",
      "14829/14829 [==============================] - 27s 2ms/step - loss: 0.0227 - acc: 0.9937 - val_loss: 0.7684 - val_acc: 0.8774\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 144/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0185 - acc: 0.9951\n",
      "Epoch 00144: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0197 - acc: 0.9949 - val_loss: 0.7603 - val_acc: 0.8780\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 145/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0193 - acc: 0.9951\n",
      "Epoch 00145: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0201 - acc: 0.9947 - val_loss: 0.7523 - val_acc: 0.8744\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 146/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0178 - acc: 0.9951\n",
      "Epoch 00146: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0196 - acc: 0.9947 - val_loss: 0.7504 - val_acc: 0.8817\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 147/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0176 - acc: 0.9955\n",
      "Epoch 00147: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0198 - acc: 0.9952 - val_loss: 0.7285 - val_acc: 0.8805\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 148/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0214 - acc: 0.9942\n",
      "Epoch 00148: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0226 - acc: 0.9939 - val_loss: 0.7197 - val_acc: 0.8823\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 149/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0204 - acc: 0.9947\n",
      "Epoch 00149: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0212 - acc: 0.9942 - val_loss: 0.7284 - val_acc: 0.8811\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 150/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0222 - acc: 0.9941\n",
      "Epoch 00150: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0242 - acc: 0.9938 - val_loss: 0.7228 - val_acc: 0.8811\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 151/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0218 - acc: 0.9938\n",
      "Epoch 00151: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0233 - acc: 0.9935 - val_loss: 0.7111 - val_acc: 0.8859\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 152/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0186 - acc: 0.9955\n",
      "Epoch 00152: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0197 - acc: 0.9953 - val_loss: 0.7204 - val_acc: 0.8792\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 153/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0175 - acc: 0.9955\n",
      "Epoch 00153: val_loss did not improve\n",
      "14829/14829 [==============================] - 27s 2ms/step - loss: 0.0187 - acc: 0.9953 - val_loss: 0.7168 - val_acc: 0.8799\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 154/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0170 - acc: 0.9954\n",
      "Epoch 00154: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0181 - acc: 0.9951 - val_loss: 0.7199 - val_acc: 0.8841\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 155/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0139 - acc: 0.9968\n",
      "Epoch 00155: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0158 - acc: 0.9964 - val_loss: 0.7060 - val_acc: 0.8823\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 156/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0161 - acc: 0.9962\n",
      "Epoch 00156: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0183 - acc: 0.9957 - val_loss: 0.7269 - val_acc: 0.8786\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 157/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0184 - acc: 0.9943\n",
      "Epoch 00157: val_loss did not improve\n",
      "14829/14829 [==============================] - 27s 2ms/step - loss: 0.0186 - acc: 0.9943 - val_loss: 0.7503 - val_acc: 0.8720\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 158/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0156 - acc: 0.9957\n",
      "Epoch 00158: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0178 - acc: 0.9952 - val_loss: 0.7159 - val_acc: 0.8805\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 159/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0165 - acc: 0.9964\n",
      "Epoch 00159: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0176 - acc: 0.9962 - val_loss: 0.7324 - val_acc: 0.8774\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 160/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0154 - acc: 0.9953\n",
      "Epoch 00160: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0170 - acc: 0.9950 - val_loss: 0.7090 - val_acc: 0.8823\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 161/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0163 - acc: 0.9949\n",
      "Epoch 00161: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0198 - acc: 0.9943 - val_loss: 0.7496 - val_acc: 0.8829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 162/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0185 - acc: 0.9951\n",
      "Epoch 00162: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0193 - acc: 0.9949 - val_loss: 0.7477 - val_acc: 0.8829\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 163/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0163 - acc: 0.9955\n",
      "Epoch 00163: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0183 - acc: 0.9951 - val_loss: 0.7066 - val_acc: 0.8841\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 164/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0167 - acc: 0.9953\n",
      "Epoch 00164: val_loss did not improve\n",
      "14829/14829 [==============================] - 27s 2ms/step - loss: 0.0184 - acc: 0.9948 - val_loss: 0.7394 - val_acc: 0.8774\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 165/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0179 - acc: 0.9942\n",
      "Epoch 00165: val_loss did not improve\n",
      "14829/14829 [==============================] - 27s 2ms/step - loss: 0.0195 - acc: 0.9939 - val_loss: 0.7127 - val_acc: 0.8780\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 166/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0160 - acc: 0.9953\n",
      "Epoch 00166: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0164 - acc: 0.9951 - val_loss: 0.7103 - val_acc: 0.8780\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 167/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0158 - acc: 0.9957\n",
      "Epoch 00167: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0175 - acc: 0.9952 - val_loss: 0.7194 - val_acc: 0.8786\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 168/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0164 - acc: 0.9955\n",
      "Epoch 00168: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0193 - acc: 0.9949 - val_loss: 0.7925 - val_acc: 0.8756\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 169/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0189 - acc: 0.9953\n",
      "Epoch 00169: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0198 - acc: 0.9949 - val_loss: 0.8052 - val_acc: 0.8671\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 170/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0184 - acc: 0.9944\n",
      "Epoch 00170: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0194 - acc: 0.9942 - val_loss: 0.7615 - val_acc: 0.8708\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 171/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0161 - acc: 0.9954\n",
      "Epoch 00171: val_loss did not improve\n",
      "14829/14829 [==============================] - 27s 2ms/step - loss: 0.0196 - acc: 0.9949 - val_loss: 0.7690 - val_acc: 0.8792\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 172/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0169 - acc: 0.9955\n",
      "Epoch 00172: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0187 - acc: 0.9952 - val_loss: 0.7883 - val_acc: 0.8817\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 173/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0155 - acc: 0.9959\n",
      "Epoch 00173: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0178 - acc: 0.9954 - val_loss: 0.7450 - val_acc: 0.8792\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 174/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0164 - acc: 0.9954\n",
      "Epoch 00174: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0172 - acc: 0.9952 - val_loss: 0.7462 - val_acc: 0.8732\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 175/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0166 - acc: 0.9954\n",
      "Epoch 00175: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0168 - acc: 0.9953 - val_loss: 0.7253 - val_acc: 0.8835\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 176/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0143 - acc: 0.9961\n",
      "Epoch 00176: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0170 - acc: 0.9958 - val_loss: 0.7069 - val_acc: 0.8817\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 177/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0149 - acc: 0.9964\n",
      "Epoch 00177: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0158 - acc: 0.9960 - val_loss: 0.7299 - val_acc: 0.8792\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 178/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0141 - acc: 0.9965\n",
      "Epoch 00178: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0153 - acc: 0.9963 - val_loss: 0.7651 - val_acc: 0.8768\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 179/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0157 - acc: 0.9961\n",
      "Epoch 00179: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0172 - acc: 0.9958 - val_loss: 0.7473 - val_acc: 0.8750\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 180/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0143 - acc: 0.9965\n",
      "Epoch 00180: val_loss did not improve\n",
      "14829/14829 [==============================] - 27s 2ms/step - loss: 0.0150 - acc: 0.9962 - val_loss: 0.7207 - val_acc: 0.8805\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 181/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0132 - acc: 0.9965\n",
      "Epoch 00181: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0140 - acc: 0.9963 - val_loss: 0.7176 - val_acc: 0.8786\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 182/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0146 - acc: 0.9960\n",
      "Epoch 00182: val_loss did not improve\n",
      "14829/14829 [==============================] - 27s 2ms/step - loss: 0.0172 - acc: 0.9953 - val_loss: 0.7194 - val_acc: 0.8829\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 183/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0156 - acc: 0.9966\n",
      "Epoch 00183: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0167 - acc: 0.9962 - val_loss: 0.7741 - val_acc: 0.8695\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 184/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0171 - acc: 0.9950\n",
      "Epoch 00184: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0173 - acc: 0.9949 - val_loss: 0.8136 - val_acc: 0.8695\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 185/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0144 - acc: 0.9957\n",
      "Epoch 00185: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0156 - acc: 0.9954 - val_loss: 0.7614 - val_acc: 0.8774\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 186/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0137 - acc: 0.9956\n",
      "Epoch 00186: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0155 - acc: 0.9952 - val_loss: 0.7715 - val_acc: 0.8799\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 187/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0158 - acc: 0.9959\n",
      "Epoch 00187: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0166 - acc: 0.9957 - val_loss: 0.8114 - val_acc: 0.8774\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 188/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0169 - acc: 0.9954\n",
      "Epoch 00188: val_loss did not improve\n",
      "14829/14829 [==============================] - 27s 2ms/step - loss: 0.0184 - acc: 0.9951 - val_loss: 0.7621 - val_acc: 0.8774\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 189/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0136 - acc: 0.9964\n",
      "Epoch 00189: val_loss did not improve\n",
      "14829/14829 [==============================] - 27s 2ms/step - loss: 0.0147 - acc: 0.9962 - val_loss: 0.7596 - val_acc: 0.8780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 190/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0130 - acc: 0.9965\n",
      "Epoch 00190: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0145 - acc: 0.9962 - val_loss: 0.7585 - val_acc: 0.8750\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 191/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0147 - acc: 0.9958\n",
      "Epoch 00191: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0162 - acc: 0.9956 - val_loss: 0.7705 - val_acc: 0.8732\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 192/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0125 - acc: 0.9964\n",
      "Epoch 00192: val_loss did not improve\n",
      "14829/14829 [==============================] - 27s 2ms/step - loss: 0.0129 - acc: 0.9964 - val_loss: 0.7687 - val_acc: 0.8701\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 193/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0128 - acc: 0.9970\n",
      "Epoch 00193: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0146 - acc: 0.9968 - val_loss: 0.7444 - val_acc: 0.8768\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 194/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0111 - acc: 0.9970\n",
      "Epoch 00194: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0121 - acc: 0.9967 - val_loss: 0.7478 - val_acc: 0.8762\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 195/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0131 - acc: 0.9964\n",
      "Epoch 00195: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0136 - acc: 0.9964 - val_loss: 0.7716 - val_acc: 0.8768\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 196/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0102 - acc: 0.9977\n",
      "Epoch 00196: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0121 - acc: 0.9972 - val_loss: 0.7889 - val_acc: 0.8762\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 197/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0166 - acc: 0.9947\n",
      "Epoch 00197: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0180 - acc: 0.9945 - val_loss: 0.8022 - val_acc: 0.8738\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 198/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0137 - acc: 0.9963\n",
      "Epoch 00198: val_loss did not improve\n",
      "14829/14829 [==============================] - 27s 2ms/step - loss: 0.0149 - acc: 0.9960 - val_loss: 0.7904 - val_acc: 0.8720\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 199/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0156 - acc: 0.9955\n",
      "Epoch 00199: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0165 - acc: 0.9953 - val_loss: 0.7801 - val_acc: 0.8744\n",
      "Learning rate = 0.0001, decay = 1\n",
      "Epoch 200/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0126 - acc: 0.9966\n",
      "Epoch 00200: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0130 - acc: 0.9964 - val_loss: 0.7558 - val_acc: 0.8768\n",
      "Learning rate = 1e-05, decay = 2\n",
      "Epoch 201/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0137 - acc: 0.9962\n",
      "Epoch 00201: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0150 - acc: 0.9960 - val_loss: 0.7451 - val_acc: 0.8774\n",
      "Learning rate = 1e-05, decay = 2\n",
      "Epoch 202/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0114 - acc: 0.9967\n",
      "Epoch 00202: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0125 - acc: 0.9965 - val_loss: 0.7414 - val_acc: 0.8762\n",
      "Learning rate = 1e-05, decay = 2\n",
      "Epoch 203/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0112 - acc: 0.9972\n",
      "Epoch 00203: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0138 - acc: 0.9966 - val_loss: 0.7435 - val_acc: 0.8786\n",
      "Learning rate = 1e-05, decay = 2\n",
      "Epoch 204/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0120 - acc: 0.9967\n",
      "Epoch 00204: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0127 - acc: 0.9964 - val_loss: 0.7486 - val_acc: 0.8750\n",
      "Learning rate = 1e-05, decay = 2\n",
      "Epoch 205/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0111 - acc: 0.9975\n",
      "Epoch 00205: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0131 - acc: 0.9970 - val_loss: 0.7490 - val_acc: 0.8762\n",
      "Learning rate = 1e-05, decay = 2\n",
      "Epoch 206/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0115 - acc: 0.9966\n",
      "Epoch 00206: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0140 - acc: 0.9962 - val_loss: 0.7467 - val_acc: 0.8750\n",
      "Learning rate = 1e-05, decay = 2\n",
      "Epoch 207/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0109 - acc: 0.9973\n",
      "Epoch 00207: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0119 - acc: 0.9970 - val_loss: 0.7463 - val_acc: 0.8762\n",
      "Learning rate = 1e-05, decay = 2\n",
      "Epoch 208/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0105 - acc: 0.9974\n",
      "Epoch 00208: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0116 - acc: 0.9972 - val_loss: 0.7471 - val_acc: 0.8780\n",
      "Learning rate = 1e-05, decay = 2\n",
      "Epoch 209/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0105 - acc: 0.9974\n",
      "Epoch 00209: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0141 - acc: 0.9968 - val_loss: 0.7408 - val_acc: 0.8799\n",
      "Learning rate = 1e-05, decay = 2\n",
      "Epoch 210/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0106 - acc: 0.9971\n",
      "Epoch 00210: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0119 - acc: 0.9968 - val_loss: 0.7358 - val_acc: 0.8799\n",
      "Learning rate = 1e-05, decay = 2\n",
      "Epoch 211/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0108 - acc: 0.9976\n",
      "Epoch 00211: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0128 - acc: 0.9972 - val_loss: 0.7339 - val_acc: 0.8811\n",
      "Learning rate = 1e-05, decay = 2\n",
      "Epoch 212/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0107 - acc: 0.9972\n",
      "Epoch 00212: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0127 - acc: 0.9969 - val_loss: 0.7383 - val_acc: 0.8799\n",
      "Learning rate = 1e-05, decay = 2\n",
      "Epoch 213/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0098 - acc: 0.9973\n",
      "Epoch 00213: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0113 - acc: 0.9970 - val_loss: 0.7412 - val_acc: 0.8774\n",
      "Learning rate = 1e-05, decay = 2\n",
      "Epoch 214/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0094 - acc: 0.9976\n",
      "Epoch 00214: val_loss did not improve\n",
      "14829/14829 [==============================] - 27s 2ms/step - loss: 0.0095 - acc: 0.9976 - val_loss: 0.7404 - val_acc: 0.8768\n",
      "Learning rate = 1e-05, decay = 2\n",
      "Epoch 215/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0105 - acc: 0.9972\n",
      "Epoch 00215: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0119 - acc: 0.9968 - val_loss: 0.7372 - val_acc: 0.8799\n",
      "Learning rate = 1e-05, decay = 2\n",
      "Epoch 216/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0103 - acc: 0.9968\n",
      "Epoch 00216: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0112 - acc: 0.9965 - val_loss: 0.7359 - val_acc: 0.8792\n",
      "Learning rate = 1e-05, decay = 2\n",
      "Epoch 217/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0101 - acc: 0.9974\n",
      "Epoch 00217: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0119 - acc: 0.9971 - val_loss: 0.7356 - val_acc: 0.8811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate = 1e-05, decay = 2\n",
      "Epoch 218/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0111 - acc: 0.9967\n",
      "Epoch 00218: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0135 - acc: 0.9962 - val_loss: 0.7332 - val_acc: 0.8817\n",
      "Learning rate = 1e-05, decay = 2\n",
      "Epoch 219/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0099 - acc: 0.9971\n",
      "Epoch 00219: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0102 - acc: 0.9970 - val_loss: 0.7348 - val_acc: 0.8817\n",
      "Learning rate = 1e-05, decay = 2\n",
      "Epoch 220/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0104 - acc: 0.9975\n",
      "Epoch 00220: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0117 - acc: 0.9970 - val_loss: 0.7358 - val_acc: 0.8841\n",
      "Learning rate = 1e-05, decay = 2\n",
      "Epoch 221/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0102 - acc: 0.9974\n",
      "Epoch 00221: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0110 - acc: 0.9972 - val_loss: 0.7327 - val_acc: 0.8835\n",
      "Learning rate = 1e-05, decay = 2\n",
      "Epoch 222/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0084 - acc: 0.9983\n",
      "Epoch 00222: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0106 - acc: 0.9978 - val_loss: 0.7287 - val_acc: 0.8835\n",
      "Learning rate = 1e-05, decay = 2\n",
      "Epoch 223/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0099 - acc: 0.9977\n",
      "Epoch 00223: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0123 - acc: 0.9974 - val_loss: 0.7254 - val_acc: 0.8829\n",
      "Learning rate = 1e-05, decay = 2\n",
      "Epoch 224/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0100 - acc: 0.9972\n",
      "Epoch 00224: val_loss did not improve\n",
      "14829/14829 [==============================] - 27s 2ms/step - loss: 0.0124 - acc: 0.9969 - val_loss: 0.7218 - val_acc: 0.8841\n",
      "Learning rate = 1e-05, decay = 2\n",
      "Epoch 225/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0096 - acc: 0.9976\n",
      "Epoch 00225: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0109 - acc: 0.9973 - val_loss: 0.7234 - val_acc: 0.8835\n",
      "Learning rate = 1e-05, decay = 2\n",
      "Epoch 226/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0090 - acc: 0.9976\n",
      "Epoch 00226: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0094 - acc: 0.9976 - val_loss: 0.7253 - val_acc: 0.8829\n",
      "Learning rate = 1e-05, decay = 2\n",
      "Epoch 227/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0078 - acc: 0.9986\n",
      "Epoch 00227: val_loss did not improve\n",
      "14829/14829 [==============================] - 27s 2ms/step - loss: 0.0084 - acc: 0.9984 - val_loss: 0.7253 - val_acc: 0.8829\n",
      "Learning rate = 1e-05, decay = 2\n",
      "Epoch 228/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0100 - acc: 0.9970\n",
      "Epoch 00228: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0116 - acc: 0.9966 - val_loss: 0.7208 - val_acc: 0.8835\n",
      "Learning rate = 1e-05, decay = 2\n",
      "Epoch 229/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0088 - acc: 0.9978\n",
      "Epoch 00229: val_loss did not improve\n",
      "14829/14829 [==============================] - 27s 2ms/step - loss: 0.0101 - acc: 0.9976 - val_loss: 0.7162 - val_acc: 0.8823\n",
      "Learning rate = 1e-05, decay = 2\n",
      "Epoch 230/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0087 - acc: 0.9978\n",
      "Epoch 00230: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0098 - acc: 0.9976 - val_loss: 0.7150 - val_acc: 0.8835\n",
      "Learning rate = 1e-05, decay = 2\n",
      "Epoch 231/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0088 - acc: 0.9979\n",
      "Epoch 00231: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0106 - acc: 0.9976 - val_loss: 0.7171 - val_acc: 0.8829\n",
      "Learning rate = 1e-05, decay = 2\n",
      "Epoch 232/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0093 - acc: 0.9975\n",
      "Epoch 00232: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0102 - acc: 0.9971 - val_loss: 0.7193 - val_acc: 0.8835\n",
      "Learning rate = 1e-05, decay = 2\n",
      "Epoch 233/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0088 - acc: 0.9980\n",
      "Epoch 00233: val_loss did not improve\n",
      "14829/14829 [==============================] - 27s 2ms/step - loss: 0.0099 - acc: 0.9977 - val_loss: 0.7155 - val_acc: 0.8829\n",
      "Learning rate = 1e-05, decay = 2\n",
      "Epoch 234/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0078 - acc: 0.9980\n",
      "Epoch 00234: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0080 - acc: 0.9978 - val_loss: 0.7113 - val_acc: 0.8841\n",
      "Learning rate = 1e-05, decay = 2\n",
      "Epoch 235/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0089 - acc: 0.9978\n",
      "Epoch 00235: val_loss did not improve\n",
      "14829/14829 [==============================] - 27s 2ms/step - loss: 0.0107 - acc: 0.9976 - val_loss: 0.7091 - val_acc: 0.8823\n",
      "Learning rate = 1e-05, decay = 2\n",
      "Epoch 236/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0089 - acc: 0.9983\n",
      "Epoch 00236: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0105 - acc: 0.9981 - val_loss: 0.7126 - val_acc: 0.8829\n",
      "Learning rate = 1e-05, decay = 2\n",
      "Epoch 237/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0096 - acc: 0.9979\n",
      "Epoch 00237: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0103 - acc: 0.9976 - val_loss: 0.7170 - val_acc: 0.8847\n",
      "Learning rate = 1e-05, decay = 2\n",
      "Epoch 238/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0082 - acc: 0.9976\n",
      "Epoch 00238: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0105 - acc: 0.9973 - val_loss: 0.7128 - val_acc: 0.8829\n",
      "Learning rate = 1e-05, decay = 2\n",
      "Epoch 239/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0083 - acc: 0.9976\n",
      "Epoch 00239: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0110 - acc: 0.9974 - val_loss: 0.7090 - val_acc: 0.8847\n",
      "Learning rate = 1e-05, decay = 2\n",
      "Epoch 240/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0085 - acc: 0.9980\n",
      "Epoch 00240: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0099 - acc: 0.9977 - val_loss: 0.7084 - val_acc: 0.8847\n",
      "Learning rate = 1e-05, decay = 2\n",
      "Epoch 241/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0088 - acc: 0.9975\n",
      "Epoch 00241: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0090 - acc: 0.9974 - val_loss: 0.7069 - val_acc: 0.8835\n",
      "Learning rate = 1e-05, decay = 2\n",
      "Epoch 242/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0086 - acc: 0.9978\n",
      "Epoch 00242: val_loss did not improve\n",
      "14829/14829 [==============================] - 27s 2ms/step - loss: 0.0092 - acc: 0.9977 - val_loss: 0.7037 - val_acc: 0.8823\n",
      "Learning rate = 1e-05, decay = 2\n",
      "Epoch 243/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0091 - acc: 0.9978\n",
      "Epoch 00243: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0119 - acc: 0.9974 - val_loss: 0.7049 - val_acc: 0.8811\n",
      "Learning rate = 1e-05, decay = 2\n",
      "Epoch 244/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0072 - acc: 0.9982\n",
      "Epoch 00244: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0086 - acc: 0.9979 - val_loss: 0.7059 - val_acc: 0.8792\n",
      "Learning rate = 1e-05, decay = 2\n",
      "Epoch 245/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0096 - acc: 0.9972\n",
      "Epoch 00245: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0101 - acc: 0.9970 - val_loss: 0.7020 - val_acc: 0.8792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate = 1e-05, decay = 2\n",
      "Epoch 246/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0082 - acc: 0.9981\n",
      "Epoch 00246: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0093 - acc: 0.9978 - val_loss: 0.7006 - val_acc: 0.8823\n",
      "Learning rate = 1e-05, decay = 2\n",
      "Epoch 247/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0084 - acc: 0.9976\n",
      "Epoch 00247: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0086 - acc: 0.9975 - val_loss: 0.7006 - val_acc: 0.8823\n",
      "Learning rate = 1e-05, decay = 2\n",
      "Epoch 248/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0098 - acc: 0.9974\n",
      "Epoch 00248: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0105 - acc: 0.9972 - val_loss: 0.6983 - val_acc: 0.8823\n",
      "Learning rate = 1e-05, decay = 2\n",
      "Epoch 249/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0090 - acc: 0.9977\n",
      "Epoch 00249: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0094 - acc: 0.9976 - val_loss: 0.6937 - val_acc: 0.8829\n",
      "Learning rate = 1e-05, decay = 2\n",
      "Epoch 250/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0084 - acc: 0.9979\n",
      "Epoch 00250: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0099 - acc: 0.9976 - val_loss: 0.6933 - val_acc: 0.8829\n",
      "Learning rate = 1e-05, decay = 2\n",
      "Epoch 251/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0089 - acc: 0.9978\n",
      "Epoch 00251: val_loss did not improve\n",
      "14829/14829 [==============================] - 27s 2ms/step - loss: 0.0101 - acc: 0.9976 - val_loss: 0.6897 - val_acc: 0.8811\n",
      "Learning rate = 1e-05, decay = 2\n",
      "Epoch 252/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0080 - acc: 0.9979\n",
      "Epoch 00252: val_loss did not improve\n",
      "14829/14829 [==============================] - 27s 2ms/step - loss: 0.0097 - acc: 0.9975 - val_loss: 0.6905 - val_acc: 0.8805\n",
      "Learning rate = 1e-05, decay = 2\n",
      "Epoch 253/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0080 - acc: 0.9980\n",
      "Epoch 00253: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0098 - acc: 0.9976 - val_loss: 0.6920 - val_acc: 0.8823\n",
      "Learning rate = 1e-05, decay = 2\n",
      "Epoch 254/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0082 - acc: 0.9982\n",
      "Epoch 00254: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0101 - acc: 0.9979 - val_loss: 0.6936 - val_acc: 0.8823\n",
      "Learning rate = 1e-05, decay = 2\n",
      "Epoch 255/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0085 - acc: 0.9977\n",
      "Epoch 00255: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0093 - acc: 0.9975 - val_loss: 0.6931 - val_acc: 0.8823\n",
      "Learning rate = 1e-05, decay = 2\n",
      "Epoch 256/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0081 - acc: 0.9982\n",
      "Epoch 00256: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0081 - acc: 0.9982 - val_loss: 0.6949 - val_acc: 0.8829\n",
      "Learning rate = 1e-05, decay = 2\n",
      "Epoch 257/20000\n",
      "14800/14829 [============================>.] - ETA: 0s - loss: 0.0084 - acc: 0.9982\n",
      "Epoch 00257: val_loss did not improve\n",
      "14829/14829 [==============================] - 28s 2ms/step - loss: 0.0093 - acc: 0.9980 - val_loss: 0.6944 - val_acc: 0.8817\n",
      "Execution time: 7209.030741214752 s\n"
     ]
    }
   ],
   "source": [
    "# store the starting time \n",
    "startTime = time.time()\n",
    "\n",
    "### config for multi-GPU ###\n",
    "fitting_result = parallel_model.fit(X_train, y_train, epochs = nb_epochs, batch_size = batchSize, shuffle = True, callbacks = [earlyStopping, checkpointer, lr], validation_data = (X_validation, y_validation))\n",
    "# fitting_result = model.fit(X_train, y_train, epochs = nb_epochs, batch_size = batchSize, shuffle = True, callbacks = [earlyStopping, checkpointer, lr], validation_data = (X_validation, y_validation))\n",
    "\n",
    "# calculate the elapsed time\n",
    "elapsed = time.time()-startTime;\n",
    "print(\"Execution time: {0} s\".format(elapsed))\n",
    "\n",
    "# save model\n",
    "model.save(modelName2Save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9f78e5c278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(19, 5))\n",
    "\n",
    "training_loss = fitting_result.history['loss']\n",
    "val_loss = fitting_result.history['val_loss']\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(training_loss, label=\"training_loss\")\n",
    "plt.plot(val_loss, label=\"validation_loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.legend(loc='best')\n",
    "\n",
    "training_acc = fitting_result.history['acc']\n",
    "val_acc = fitting_result.history['val_acc']\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(training_acc, label=\"training_acc\")\n",
    "plt.plot(val_acc, label=\"validation_acc\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"acc\")\n",
    "plt.title(\"Training Accuracy\")\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the output (probabilistics) to classes\n",
    "def proba_to_class(a):\n",
    "    classCount = len(a[0])\n",
    "    print('proba_to_class:classCount={}'.format(classCount)) #M:\n",
    "    to_return = np.empty((0,classCount))\n",
    "    for row in a:\n",
    "        maxind = np.argmax(row)\n",
    "        to_return = np.vstack((to_return, [1 if i == maxind else 0 for i in range(classCount)]))\n",
    "    return to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20, 69, 39, ..., 24, 39, 13])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate metrics on test data with the last model \n",
    "from sklearn.metrics import average_precision_score, accuracy_score\n",
    "y_result = model.predict(X_test)\n",
    "y_argmax = np.argmax(y_result, axis=1)\n",
    "y_argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20, 69, 39, ..., 24, 39, 13])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_real = np.argmax(y_test, axis=1)\n",
    "y_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AveragePrecision: 0.9386581899571382\n",
      "proba_to_class:classCount=123\n",
      "Accuracy: 0.8880393227744402\n"
     ]
    }
   ],
   "source": [
    "# calculate metrics on test data with the last model \n",
    "from sklearn.metrics import average_precision_score, accuracy_score\n",
    "\n",
    "map = average_precision_score(y_test, y_result, average='micro')\n",
    "print(\"AveragePrecision: {}\".format(map))\n",
    "\n",
    "accuracy = accuracy_score(y_test, proba_to_class(y_result))\n",
    "print(\"Accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # reload the best model with smallest validation loss and calculate metrics on test data\n",
    "# print(\"----- Loading best model from: {}  -------\".format(bestModelFilePath_val_loss))\n",
    "# model.load_weights(bestModelFilePath_val_loss)\n",
    "# y_result_bm = model.predict(X_test)\n",
    "# map_bm_val_loss = average_precision_score( y_test.data[y_test.start: y_test.end], y_result_bm, average='macro')\n",
    "# accuracy_bm_val_loss = accuracy_score(y_test.data[y_test.start: y_test.end], proba_to_class(y_result_bm))\n",
    "# print(\"AveragePrecision: {}\".format(map_bm_val_loss))\n",
    "# print(\"Accuracy: {}\".format(accuracy_bm_val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # reload the best model with highest validation accuracy and calculate metrics on test data\n",
    "# print(\"----- Loading best model from: {}  -------\".format(bestModelFilePath_val_acc))\n",
    "# model.load_weights(bestModelFilePath_val_acc)\n",
    "# y_result_bm = model.predict(X_test)\n",
    "# map_bm_val_acc = average_precision_score( y_test.data[y_test.start: y_test.end], y_result_bm, average='macro')\n",
    "# accuracy_bm_val_acc = accuracy_score(y_test.data[y_test.start: y_test.end], proba_to_class(y_result_bm))\n",
    "# print(\"AveragePrecision: {}\".format(map_bm_val_acc))\n",
    "# print(\"Accuracy: {}\".format(accuracy_bm_val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save the results summery into an excel file\n",
    "# import log\n",
    "# log.logToXLS(logfileName, model, fitting_result, {'execution(s)':elapsed, 'map':map, 'accuracy':accuracy, 'map_bm_val_loss':map_bm_val_loss, 'accuracy_bm_val_loss':accuracy_bm_val_loss,'map_bm_val_acc':map_bm_val_acc, 'accuracy_bm_val_acc':accuracy_bm_val_acc, 'modelPyFile': modelPath})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
